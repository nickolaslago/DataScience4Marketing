{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.ticker as mtick\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Some useful defined functions that you can use and modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification(y_test, y_pred):\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    # Classification Report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize = (5,3))\n",
    "    ax = sns.heatmap(cm, annot=True, fmt='g', cmap = 'Blues')\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(features, importance):\n",
    "    df_importance = pd.DataFrame({'Feature': features, 'Importance': importance})\n",
    "    df_importance['Impact'] = ['Positive' if x > 0 else 'Negative' for x in df_importance['Importance']]\n",
    "    df_importance.sort_values(by = 'Importance', ascending = False, inplace = True)\n",
    "\n",
    "    plt.figure(figsize = (6,8))\n",
    "    sns.barplot(data = df_importance, x = 'Importance', y = 'Feature', hue = 'Impact', hue_order = ['Negative', 'Positive'])\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(y_test, y_pred, revenue, cost):\n",
    "    from sklearn.metrics import confusion_matrix \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    total_cost = (cm[0][1] + cm[1][1]) * cost\n",
    "    total_revenue = (cm[1][1]) * revenue\n",
    "    profit = total_revenue - total_cost\n",
    "    return profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Data\n",
    "Start by importing the `customer_data.xlsx` file into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows and columns does our dataset have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the cost per contact (4€) and the revenue per positive answer (50€), what was the total profit of the last Marketing campaing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are expert Data Scientists and we know the dangers of overfitting, let's split our data like so:\n",
    "* 80% Trainning\n",
    "* 20% Testing\n",
    "\n",
    "_Since we are dealing with a binary classification problem, remember to keep the same proportion of positive responses in each subset!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dimensionality of each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the response rate in each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Types\n",
    "Start the EDA by checking the data types in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data summary\n",
    "For each data type `numerical`, `object`, and `datetime`, let's see some summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the following boxplot. What can you conclude on the customers preference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "train[['Clothes','Kitchen','SmallAppliances','HouseKeeping','Toys']].boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a seaborn countplot, check the distribution of categories for `Gender`, `Education`, and `Marital_Status`\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.countplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = ..., data = ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Missing Values\n",
    "Missing data is always a No-No. How many missings do we have per feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check them visually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na = pd.DataFrame(train.isna().sum()/train.shape[0],\n",
    "                        columns = ['Missings (%)']).sort_values(by = 'Missings (%)', ascending = False)\n",
    "df_na = df_na[df_na['Missings (%)'] > 0].copy()\n",
    "\n",
    "plt.figure(figsize = (6,4))\n",
    "ax = sns.barplot(data = df_na, x = df_na.index, y = 'Missings (%)' )\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "plt.title('Missing Values (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Correlation\n",
    "Display the correlation between all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you represent the correlation visually?\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmap = sns.diverging_palette(220, 20, as_cmap=True) optional colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Mnt` and `Frq` seem very highly correlated. Display this relationship with a scatterplot. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing\n",
    "In this section we will transform our data to better fit an analytical model. Remember that all decisions have to be made based on the __Training__ set but replicated on the __Testing__ set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Drop Correlated Features\n",
    "Let's look at the pairs with over 90% correlation and drop one of the features. They are basically giving the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frq, CatPurchase, Year_Birth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Fix Missing Values\n",
    "Since there are some missing values, let's use a simple strategy of imputing the missings using the median value of numerical features. For features of type Object, use the most frequent category (mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confirm you solved the problem\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. New Features / Encoding\n",
    "Usually in a problem, we go beyond the features that already exist in our data. In fact, the features we create based on our business knowledge will probably be more important for predictions than the original ones. Having said this, create the following variables:\n",
    "* __Days as Customer__ - Nr. of days as customer\n",
    "* __Female__ - 1 if customer is Female, 0 if Male\n",
    "* __High_Educ__ - 1 if customer has high education (Graduation, Master, or PhD)\n",
    "* __Marital Status__ (One-Hot-Encoding) - One dummy binary feature for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days as Customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Dt_Customer', 'Days_as_customer']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Gender', 'Female']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High Educ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Education', 'High_Educ']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marital Status -> One-Hot-Encoding (with prefix MS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Marital_Status', 'MS_Married', 'MS_Single', 'MS_Together', 'MS_Widow']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the initial variables: `Dt_Customer`, `Gender`, `Education`, and `Marital_Status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Split data into X and Y\n",
    "We are almost done with preprocessing our data. To make things easier, let's divide our data into independent (what we use to predict) and dependent (what we want to predict) features:\n",
    "* __x_train__ - all training data except `Custid` and `Response`\n",
    "* __y_train__ - training `Response`\n",
    "* __x_test__ - all testing data except `Custid` and `Response`\n",
    "* __y_test__ - testing `Response`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you missed any previous step, use this checkpoint to import the dataset we created until now.\n",
    "\n",
    "#train = pd.read_excel('customer_data_checkpoint.xlsx', sheet_name = 'train', index_col = 0)\n",
    "#test = pd.read_excel('customer_data_checkpoint.xlsx', sheet_name = 'test', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Normalize\n",
    "Since we have features in different scale, it is common to normalize the data to avoid future problems. Let's try the Min-Max scaler that fits all values between 0 and 1 in the __x_train__ and __x_test__ subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Train\n",
    "\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first 5 rows of the __x_train__ subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model\n",
    "Now the cool part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. The Old Way\n",
    "Using the old method (sending the offer to every customer), estimate the profit you would get in the testing subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit = get_profit(y_test = y_test, y_pred = y_pred, revenue = revenue, cost = cost)\n",
    "print('Total Profit: {} €'.format(profit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Logistic Regression\n",
    "Using a Logistic Regression, train a model in the training set and predict the response in the testing set. Then, calculate some main performance measures (Accuracy, Precision, Recall, F1-Score), print the feature importance and estimate the profit.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit = \n",
    "print('Total Profit: {} €'.format(profit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a barplot that displays the profit on the testing set by using the Old method and a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Model': [..., ...],\n",
    "                        'Profit': [..., ...]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. EXTRA\n",
    "What happens if we try a different model? A Decision Tree for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "model = model.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_classification(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x_train_scaled.columns\n",
    "importance = model.feature_importances_\n",
    "\n",
    "df_importance = pd.DataFrame({'Feature': features, 'Importance': importance})\n",
    "df_importance.sort_values(by = 'Importance', ascending = False, inplace = True)\n",
    "\n",
    "plt.figure(figsize = (5,7))\n",
    "sns.barplot(data = df_importance, x = 'Importance', y = 'Feature', color = 'salmon')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Decision Tree with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the most important features\n",
    "\n",
    "cols = ['Mnt', 'Days_as_customer', 'Income', 'Rcn', 'NetPurchase', 'Toys', \n",
    "        'SmallAppliances', 'HouseKeeping', 'Kitchen', 'High_Educ']\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "model = model.fit(x_train_scaled[cols], y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_scaled[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_classification(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_dict = {}\n",
    "# Old way\n",
    "y_pred = [1] * len(y_test)\n",
    "profit_dict['Old Way'] = get_profit(y_test = y_test, y_pred = y_pred, revenue = revenue, cost = cost)\n",
    "\n",
    "# Logistic\n",
    "y_pred = LogisticRegression(random_state=0).fit(x_train_scaled, y_train).predict(x_test_scaled)\n",
    "profit_dict['Logistic Regression'] = get_profit(y_test = y_test, y_pred = y_pred, revenue = revenue, cost = cost)\n",
    "\n",
    "# Decision Tree\n",
    "y_pred = DecisionTreeClassifier(random_state=0).fit(x_train_scaled, y_train).predict(x_test_scaled)\n",
    "profit_dict['Decision Tree'] = get_profit(y_test = y_test, y_pred = y_pred, revenue = revenue, cost = cost)\n",
    "\n",
    "# Decision Tree with selection\n",
    "cols = ['Mnt', 'Days_as_customer', 'Income', 'Rcn', 'NetPurchase', 'Toys','SmallAppliances', 'HouseKeeping', 'Kitchen', 'High_Educ']\n",
    "y_pred = DecisionTreeClassifier(random_state=0).fit(x_train_scaled[cols], y_train).predict(x_test_scaled[cols])\n",
    "profit_dict['Decision Tree (w selection)'] = get_profit(y_test = y_test, y_pred = y_pred, revenue = revenue, cost = cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame.from_dict(profit_dict, orient = 'Index').reset_index()\n",
    "models.columns = ['Model', 'Profit']\n",
    "print(models.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the `models` DataFrame has 2 columns: _Model_ and _Profit_ , can you draw a barplot that ilustrates each Model and Profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.barplot(data = models, x = 'Model', y = 'Profit')\n",
    "plt.title('Models Profit')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
