{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "##### Social Media Analytics\n",
    "### Introduction to Text Mining\n",
    "## Text Annotation\n",
    "(c) Nuno Antonio 2019-2021"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Initial setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "b'Skipping line 12799: expected 21 fields, saw 23\\n'\nb'Skipping line 37247: expected 21 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dtypes = {'RevID':'category','Source':'category','HotelID':'category',\n",
    "  'HotelType':'category','HotelStars':'category','ObsDateGlobalRating':'float64',\n",
    "  'Language':'category','RevUserName':'category','RevUserLocation':'category','RevOverallRating':'float64'}\n",
    "ds = pd.DataFrame(pd.read_csv(\"HotelOnlineReviews.txt\",sep=\"|\", \n",
    "  error_bad_lines=False, dtype=dtypes, decimal=',', index_col='RevID'))"
   ]
  },
  {
   "source": [
    "### Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def textPreProcess(rawText, removeHTML=True, charsToRemove = r'\\?|\\.|\\!|\\;|\\.|\\\"|\\,|\\(|\\)|\\&|\\:|\\-', removeNumbers=True, removeLineBreaks=False, specialCharsToRemove = r'[^\\x00-\\xfd]', convertToLower=True, removeConsecutiveSpaces=True):\n",
    "    cleanedText = []\n",
    "    for x in (rawText[:]): \n",
    "        \n",
    "        # Remove HTML\n",
    "        if removeHTML:\n",
    "            procText = BeautifulSoup(x,'html.parser').get_text()\n",
    "\n",
    "         # Remove punctuation and other special characters\n",
    "        if len(charsToRemove)>0:\n",
    "            procText = re.sub(charsToRemove,' ',procText)\n",
    "\n",
    "        # Remove numbers\n",
    "        if removeNumbers:\n",
    "            procText = re.sub(r'\\d+',' ',procText)\n",
    "\n",
    "        # Remove line breaks\n",
    "        if removeLineBreaks:\n",
    "            procText = procText.replace('\\n',' ').replace('\\r', '')\n",
    "\n",
    "        # Remove special characters\n",
    "        if len(specialCharsToRemove)>0:\n",
    "            procText = re.sub(specialCharsToRemove,' ',procText)\n",
    "\n",
    "        # Normalize to lower case\n",
    "        if convertToLower:\n",
    "            procText = procText.lower() \n",
    "\n",
    "        # Replace multiple consecutive spaces with just one space\n",
    "        if removeConsecutiveSpaces:\n",
    "            procText = re.sub(' +', ' ', procText)\n",
    "\n",
    "        # If there is a text, add it to the clean text         \n",
    "        if procText != '':\n",
    "            cleanedText.append(procText)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts\n",
    "def tokenize_words(texts):\n",
    "    words_new = []\n",
    "    for w in (texts[:]):\n",
    "        w_token = word_tokenize(w)\n",
    "        if w_token != '':\n",
    "            words_new.append(w_token)\n",
    "    return words_new"
   ]
  },
  {
   "source": [
    "### Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only the description\n",
    "processedReviews =  pd.DataFrame(data=textPreProcess(ds.RevDescription), index=ds.index, columns=['PreProcessedText']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "processedReviews['Words'] =  tokenize_words(processedReviews['PreProcessedText'])"
   ]
  },
  {
   "source": [
    "#### English"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('we', 'PRP'), ('stayed', 'VBD'), ('nights', 'NNS'), ('at', 'IN'), ('this', 'DT'), ('resort', 'NN'), ('in', 'IN'), ('july/august', 'NN'), ('we', 'PRP'), ('stayed', 'VBD'), ('in', 'IN'), ('a', 'DT'), ('suitte', 'NN'), ('appartment', 'NN'), ('which', 'WDT'), ('was', 'VBD'), ('very', 'RB'), ('nice', 'JJ'), ('the', 'DT'), ('appartment', 'NN'), ('had', 'VBD'), ('two', 'CD'), ('floors', 'NNS'), ('and', 'CC'), ('everything', 'NN'), ('needed', 'VBN'), ('for', 'IN'), ('a', 'DT'), ('nice', 'JJ'), ('vacation', 'NN'), ('the', 'DT'), ('staff', 'NN'), ('was', 'VBD'), ('friendly', 'RB'), ('and', 'CC'), ('service', 'VB'), ('good', 'JJ'), ('at', 'IN'), ('this', 'DT'), ('buy', 'NN'), ('time', 'NN'), ('of', 'IN'), ('year', 'NN'), ('we', 'PRP'), ('found', 'VBD'), ('the', 'DT'), ('common', 'JJ'), ('area', 'NN'), ('with', 'IN'), ('pools', 'NNS'), ('etc', 'VBP'), ('a', 'DT'), ('little', 'JJ'), ('bit', 'NN'), ('to', 'TO'), ('small', 'JJ'), ('and', 'CC'), ('crowded', 'VBD'), ('the', 'DT'), ('gym', 'NN'), ('could', 'MD'), ('not', 'RB'), ('really', 'RB'), ('be', 'VB'), ('called', 'VBN'), ('a', 'DT'), ('gym', 'NN'), ('and', 'CC'), ('two', 'CD'), ('people', 'NNS'), ('inside', 'IN'), ('there', 'EX'), ('was', 'VBD'), ('a', 'DT'), ('crowd', 'NN'), ('having', 'VBG'), ('said', 'VBD'), ('that', 'IN'), ('we', 'PRP'), ('liked', 'VBD'), ('the', 'DT'), ('resort', 'NN'), ('both', 'DT'), ('the', 'DT'), ('location', 'NN'), ('and', 'CC'), ('the', 'DT'), ('quality', 'NN'), ('of', 'IN'), ('the', 'DT'), ('buildings', 'NNS'), ('we', 'PRP'), ('never', 'RB'), ('tried', 'VBD'), ('the', 'DT'), ('restaurant', 'NN'), ('as', 'IN'), ('we', 'PRP'), ('like', 'VBP'), ('to', 'TO'), ('seek', 'VB'), ('up', 'RP'), ('local', 'JJ'), ('restaurants', 'NNS'), ('and', 'CC'), ('also', 'RB'), ('some', 'DT'), ('favorites', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('area', 'NN'), ('the', 'DT'), ('resort', 'NN'), ('is', 'VBZ'), ('close', 'RB'), ('to', 'TO'), ('my', 'PRP$'), ('favorite', 'JJ'), ('restaurant', 'NN'), ('in', 'IN'), ('carvoeiro', 'NN'), ('bon', 'NN'), ('bon', 'NN'), ('restaurant', 'NN'), ('carvoeiro', 'NN'), ('village', 'NN'), ('is', 'VBZ'), ('very', 'RB'), ('nice', 'JJ'), ('with', 'IN'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('good', 'JJ'), ('restaurant', 'NN'), ('and', 'CC'), ('in', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('pictures', 'NNS'), ('area', 'NN'), ('of', 'IN'), ('the', 'DT'), ('algarve', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# ENGLISH POS Tagg - Using NLTK\n",
    "tags = nltk.pos_tag(processedReviews.Words['T4617'])\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['nights', 'resort', 'july/august', 'suitte', 'appartment', 'appartment', 'floors', 'everything', 'vacation', 'staff', 'buy', 'time', 'year', 'area', 'pools', 'bit', 'gym', 'gym', 'people', 'crowd', 'resort', 'location', 'quality', 'buildings', 'restaurant', 'restaurants', 'favorites', 'area', 'resort', 'restaurant', 'carvoeiro', 'bon', 'bon', 'restaurant', 'carvoeiro', 'village', 'lot', 'restaurant', 'pictures', 'area', 'algarve']\n"
     ]
    }
   ],
   "source": [
    "# Filter only Nouns\n",
    "nouns = []\n",
    "for tag in tags:\n",
    "    if tag[1][0]==\"N\":  # if if starts with a \"N\"\n",
    "        nouns.append(tag[0])\n",
    "print(nouns)"
   ]
  },
  {
   "source": [
    "#### Spanish"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "el DET\nenclave NOUN\ndel ADP\nhotel NOUN\nes AUX\ntan ADV\nespectacular ADJ\nque SCONJ\nlas DET\nvistas NOUN\nquitan AUX\nla DET\nrespiración NOUN\nla DET\npiscina NOUN\nes AUX\nuna DET\nauténtica ADJ\ngozada ADJ\nlas DET\nhabitaciones NOUN\nson VERB\ngrandes ADJ\ny CCONJ\ntranquilas ADJ\nlo PRON\nque SCONJ\nlas PRON\nhace AUX\ncómodas ADJ\npero CCONJ\nla DET\ndecoración NOUN\ny CCONJ\nlos DET\nbaños NOUN\nestán VERB\nrealmente ADV\nanticuados ADJ\nel DET\ndesayuno NOUN\nnos PRON\nresultó VERB\nun DET\npoco ADV\ndecepcionante ADJ\nno ADV\npor ADP\nla DET\ncantidad NOUN\nsino CCONJ\npor ADP\nla DET\ncalidad NOUN\ntodo PRON\nes AUX\nbastante ADV\ncorriente ADJ\ny CCONJ\nsorprende VERB\npor ADP\nejemplo NOUN\ntener VERB\nsolo ADV\nun DET\ntipo NOUN\nde ADP\nqueso NOUN\ncuando SCONJ\nhasta ADV\nen ADP\nel DET\nsupermercado NOUN\nte PRON\ndesborda VERB\nla DET\nvariedad NOUN\nde ADP\nquesos NOUN\nde ADP\nla DET\nzona NOUN\ny CCONJ\npatés VERB\n"
     ]
    }
   ],
   "source": [
    "# SPANNISH POS Tagg - Using Spacy\n",
    "import spacy    # May require installation\n",
    "nlp = spacy.load(\"es_core_news_sm\") # Load language model (python -m spacy download es_core_news_sm). More models in https://spacy.io/models\n",
    "result = nlp(processedReviews.PreProcessedText['T7883'])\n",
    "for token in result:\n",
    "  print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[espectacular, auténtica, gozada, grandes, tranquilas, cómodas, anticuados, decepcionante, corriente]\n"
     ]
    }
   ],
   "source": [
    "# Filter only Adjectives\n",
    "adjectives = []\n",
    "for token in result:\n",
    "    if token.pos_==\"ADJ\":\n",
    "        adjectives.append(token)\n",
    "print(adjectives)"
   ]
  },
  {
   "source": [
    "#### Portuguese"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "é AUX\num DET\nhotel NOUN\nbastante ADV\nbom ADJ\npara ADP\nfamílias NOUN\ncom ADP\ncrianças NOUN\nas DET\nmoradias NOUN\nindividuais ADJ\npermitem VERB\nestar AUX\nmais DET\nvontade NOUN\ne CCONJ\nassim ADV\ngozar VERB\nmais ADV\nos DET\nespaço NOUN\né AUX\num DET\npouco ADV\nafastado VERB\nda DET\npraia NOUN\nmas CCONJ\ncompensa VERB\npela DET\ncalma NOUN\ne CCONJ\nsossego VERB\no DET\npessoal NOUN\né AUX\nmuito ADV\nagradável ADJ\ne CCONJ\nprestável ADJ\na DET\ncomida NOUN\né AUX\nboa ADJ\ne CCONJ\nas DET\nacomodações NOUN\nmodernas ADJ\ntem VERB\napenas ADV\num NUM\nsenão ADV\no DET\nbarulho NOUN\ndas DET\nrãs ADV\ndurante ADP\na DET\nnoite NOUN\n"
     ]
    }
   ],
   "source": [
    "# PORTUGUESE POS Tagg - Using Spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")           # Load language model (python -m spacy download pt_core_news_sm). More models in https://spacy.io/models\n",
    "result = nlp(processedReviews.PreProcessedText['T4914'])\n",
    "for token in result:\n",
    "  print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[permitem, gozar, afastado, compensa, sossego, tem]\n"
     ]
    }
   ],
   "source": [
    "# Filter only Verbs\n",
    "verbs = []\n",
    "for token in result:\n",
    "    if token.pos_==\"VERB\":\n",
    "        verbs.append(token)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}